# 🧭 Week 7 Assignment – AI Ethics, Bias & Responsible AI

## 📘 Overview

This assignment explores critical ethical dimensions of AI development and deployment, including algorithmic bias, transparency, GDPR, fairness auditing, and responsible use of AI in sensitive domains such as healthcare and law enforcement.

---

## 🧠 Part 1: Theoretical Understanding (30%)

### 1. Short Answer Questions

- **Q1:** Defined *algorithmic bias* and provided real-world examples of bias in AI hiring and facial recognition systems.
- **Q2:** Explained the difference between *transparency* (how open the system is) and *explainability* (how well we understand its decisions).
- **Q3:** Analyzed how *GDPR* impacts AI development in the EU, especially in terms of consent, data minimization, and right to explanation.

### 2. Ethical Principles Matching

Matched ethical principles to their correct definitions:
- **Justice** – Fair distribution of AI benefits and risks  
- **Non-maleficence** – Ensuring AI does not harm individuals or society  
- **Autonomy** – Respecting users’ right to control their data and decisions  
- **Sustainability** – Designing AI to be environmentally friendly  

---

## 🕵️ Part 2: Case Study Analysis (40%)

### Case 1: Biased Hiring Tool (Amazon)

- Identified **biased training data** (male-dominated past resumes) as the root cause.
- Proposed **3 mitigation strategies**:
  - Balanced training dataset  
  - Remove gendered keywords  
  - Add fairness constraints in model training
- Suggested **fairness metrics**:
  - Demographic parity  
  - Equal opportunity  
  - False positive/negative rates by gender

### Case 2: Facial Recognition in Policing

- Discussed **ethical risks**: racial profiling, privacy violations, wrongful arrests.
- Recommended **deployment policies**:
  - Human-in-the-loop review  
  - Transparency logs  
  - Moratorium in sensitive areas (e.g., protests)

---

## 🧪 Part 3: Practical Audit (25%)

- Audited the **COMPAS Recidivism Dataset** using IBM’s **AI Fairness 360 Toolkit**.
- Visualized racial disparities in **false positive rates**.
- Wrote a 300-word report:
  - Summarizing bias findings  
  - Recommending use of reweighing and adversarial debiasing methods  
  - Stressed importance of ongoing audits

---

## ✍️ Part 4: Ethical Reflection (5%)

- Reflected on a personal or future AI project.
- Described steps to ensure adherence to ethical AI principles:
  - Fairness audits  
  - Data privacy  
  - Transparent reporting

---

## 🏥 Bonus Task: Policy Proposal (Extra 10%)

### Ethical AI Use in Healthcare – 1-Page Guideline

**Includes:**
- **Patient Consent Protocols**: Informed, revocable, and transparent
- **Bias Mitigation Strategies**: Diverse datasets, continuous audits
- **Transparency Requirements**: Explainable models and audit trails

---

## 👥 Contributors

**Group 61**  
1. Joyce Njihia – nyamburanjihia@gmail.com  
2. Gospel Arinze – gospelarinzestuff@gmail.com  
3. Ling Mukiri – lingmukiri13@gmail.com  
4. Juma Calvin – jumacavin28@gmail.com  
5. Esther Trizar – esthertrizar@gmail.com  

---

## 📎 Submission Note

Thank you for reviewing our submission. Kindly see the attached PDF report and source code files (where applicable) for:

- Full theoretical responses  
- Case study solutions  
- Bias audit visualizations and metrics  
- Ethical policy recommendations  
